{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN2D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pJr2QX16y0C"
      },
      "source": [
        "# **Préparer les données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI65qFkLjyEY"
      },
      "source": [
        "### **Monter le dossier dans Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVb5j_uZDvRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22eadcb9-cf07-43d0-ba8d-882a970a630a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DcknGEsEkrE"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEIWGiCq_s3g"
      },
      "source": [
        "### **Importation de quelques librairies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HzSSHr5ooul"
      },
      "source": [
        "import numpy as np\n",
        "import tifffile\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVrWVyvfkBDD"
      },
      "source": [
        "### **Lecture de la série temporelle d'images et Normalisation par bande sur la série temporelle entre 0 et 1** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95CB2_IllQFu"
      },
      "source": [
        "#### **Lecture des images et création des séries temporelles de bandes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut67k4u3Vezu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7908145b-f1ae-4f5a-d215-72cf9ad85351"
      },
      "source": [
        "# Récupérer la liste des images\n",
        "lst_img = glob.glob ('Images/*.tif')\n",
        "lst_img.sort() # ordonner par date si ce n'est pas le cas\n",
        "lst_img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Images/20160322_S2A.tif',\n",
              " 'Images/20160710_S2A.tif',\n",
              " 'Images/20160730_S2A.tif',\n",
              " 'Images/20160928_S2A.tif',\n",
              " 'Images/20161018_S2A.tif',\n",
              " 'Images/20161127_S2A.tif',\n",
              " 'Images/20161217_S2A.tif',\n",
              " 'Images/20161227_S2A.tif']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSpMjDMNa-Bg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488362ad-7582-4d12-ab89-f6e3e62636b2"
      },
      "source": [
        "# Lecture de la bande du rouge (B1) pour toute la série temporelle\n",
        "red_ts = []\n",
        "for img in lst_img:\n",
        "  red_ts.append( tifffile.imread(img)[:,:,0]) # Rouge\n",
        "red_ts = np.dstack(red_ts)\n",
        "red_ts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5412, 5592, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X97WsP3kcTL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579aa935-c171-4ae6-dece-7c4b82e658fc"
      },
      "source": [
        "# Lecture de la bande du vert (B2) pour toute la série temporelle\n",
        "green_ts = []\n",
        "for img in lst_img:\n",
        "  green_ts.append( tifffile.imread(img)[:,:,1]) # Vert\n",
        "green_ts = np.dstack(green_ts)\n",
        "green_ts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5412, 5592, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1GBdVCGcbcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e747c0-f3a5-4289-e571-3ead3803f1c6"
      },
      "source": [
        "# Lecture de la bande du bleu (B3) pour toute la série temporelle\n",
        "blue_ts = []\n",
        "for img in lst_img:\n",
        "  blue_ts.append( tifffile.imread(img)[:,:,2]) # Bleu\n",
        "blue_ts = np.dstack(blue_ts)\n",
        "blue_ts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5412, 5592, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDd4BjV-cbz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a2d6b0-984e-45c1-de54-eab7459c23ef"
      },
      "source": [
        "# Lecture de la bande du proche infrarouge (B4) pour toute la série temporelle\n",
        "nir_ts = []\n",
        "for img in lst_img:\n",
        "  nir_ts.append( tifffile.imread(img)[:,:,3]) # Proche infra rouge\n",
        "nir_ts = np.dstack(nir_ts)\n",
        "nir_ts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5412, 5592, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJVBYJxuuJDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d1e0f7-278d-40ea-e0c4-5be70ff68fcf"
      },
      "source": [
        "# Calculer des indices spectraux comme le NDVI\n",
        "ndvi_ts = np.where(nir_ts + red_ts == 0, 0, (nir_ts - red_ts) / (nir_ts + red_ts)).astype(np.float32)\n",
        "ndvi_ts.shape, ndvi_ts.dtype, ndvi_ts.min(), ndvi_ts.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5412, 5592, 8), dtype('float32'), -0.9994976, 0.99976385)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOOWsKQHlHvS"
      },
      "source": [
        "#### **Normalisation en utilisant le min et le max des bandes sur les séries temporelles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoOk5-UccvSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c0d5d5-87fe-4c8e-f50c-a9a9cd50a969"
      },
      "source": [
        "# Normalisation des séries temporelles par bande: Rouge\n",
        "red_ts_norm = ( red_ts - red_ts.min() ) / ( red_ts.max() - red_ts.min() ).astype(np.float32)\n",
        "red_ts_norm.min() , red_ts_norm.max(), red_ts_norm.shape, red_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c1DlhJTe_6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87800602-8f1f-49b1-cd40-86123dcd81d8"
      },
      "source": [
        "# Normalisation des séries temporelles par bande: Vert\n",
        "green_ts_norm = ( green_ts - green_ts.min() ) / ( green_ts.max() - green_ts.min() ).astype(np.float32)\n",
        "green_ts = None\n",
        "green_ts_norm.min() , green_ts_norm.max(), green_ts_norm.shape, green_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFNAbyIyfAJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5965fa3c-b482-4fde-f424-cb1de8fd0a27"
      },
      "source": [
        "# Normalisation des séries temporelles par bande: Bleu\n",
        "blue_ts_norm = ( blue_ts - blue_ts.min() ) / ( blue_ts.max() - blue_ts.min() ).astype(np.float32)\n",
        "blue_ts = None\n",
        "blue_ts_norm.min() , blue_ts_norm.max(), blue_ts_norm.shape, blue_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epIhb6brfAUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea612b9-b255-47b3-9b4f-d34338035a08"
      },
      "source": [
        "# Normalisation des séries temporelles par bande: Proche infrarouge\n",
        "nir_ts_norm = ( nir_ts - nir_ts.min() ) / ( nir_ts.max() - nir_ts.min() ).astype(np.float32)\n",
        "nir_ts_norm.min() , nir_ts_norm.max(), nir_ts_norm.shape, nir_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAtrTnz_uQ2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64abfb46-1835-4b3d-f0a4-083787dd8f84"
      },
      "source": [
        "# Normaliser les indices spectraux que vous aurez calculé\n",
        "ndvi_ts_norm = ( ndvi_ts - ndvi_ts.min() ) / ( ndvi_ts.max() - ndvi_ts.min( )).astype(np.float32)\n",
        "ndvi_ts_norm.min(), ndvi_ts_norm.max(), ndvi_ts_norm.shape, ndvi_ts_norm.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0, (5412, 5592, 8), dtype('float32'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDQUbh3Nkpn7"
      },
      "source": [
        "### **Lecture de la vérité terrain et récupération des positions des pixels du jeu d'entraînement et de test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_mXEBEKmuw7"
      },
      "source": [
        "#### **Lecture des fichiers de la vérité terrain**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBCQhbMUoBJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29550d1b-6e7c-4daa-d7ed-8a2a8267bb56"
      },
      "source": [
        "# Lire le fichier correspondant aux classes d'occupation du sol\n",
        "gt_class = tifffile.imread ('Verite_terrain/DORDOGNE_VT_CLASS.tif')\n",
        "gt_class.shape , gt_class.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5412, 5592), dtype('uint8'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLnTil_psMLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a77411-e613-40ff-95d2-1557cb3fed53"
      },
      "source": [
        "# Lire le fichier correspondant aux identifiants\n",
        "gt_id = tifffile.imread ('Verite_terrain/DORDOGNE_VT_ID.tif')\n",
        "gt_id.shape, gt_id.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5412, 5592), dtype('int16'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjyGTdRpm5ii"
      },
      "source": [
        "#### **Récupération des positions des pixels d'entraînement et de test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yosWk1_BgiLE"
      },
      "source": [
        "# Récupérer les positions des échantillons d'entraînement et test\n",
        "idx_train_ = np.where ( (gt_id!=0) & (gt_class!=0) )\n",
        "idx_test = np.where ( (gt_id!=0) & (gt_class==0) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRX0xj4zjvVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "92d53baf-9c1c-4f31-f7dc-b3bade7e1af3"
      },
      "source": [
        "# Lecture des identifiants et labels des échantillons d'entraînement\n",
        "train_id_ = gt_id[idx_train_]\n",
        "train_y_ = gt_class[idx_train_]\n",
        "f'échantillons d\\'entrainement: {train_y_.shape[0]} pixels, {len(np.unique(train_id_))} objets'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"échantillons d'entrainement: 605431 pixels, 1859 objets\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiPCaHQ2jtZu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2d3f09d6-1b04-4a62-de6b-23d0579e3353"
      },
      "source": [
        "# Lecture des identifiants et labels des échantillons de test\n",
        "test_id = gt_id[idx_test]\n",
        "f'échantillons test: {test_id.shape[0]} pixels, {len(np.unique(test_id))} objets'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'échantillons test: 207485 pixels, 800 objets'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNFyNkc5oc6z"
      },
      "source": [
        "### **Création d'un jeu de validation en prenant une partie du jeu d'entraînement**\n",
        "Pour cela, on s'assure de faire la division en mettant les pixels ayant le même identifiant dans un seul et même lot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hI-jAEqrac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4e81ca68-4e59-4638-e36c-0fc41ded6af0"
      },
      "source": [
        "# Dataframe pour créer un jeu de validation\n",
        "samples = pd.DataFrame({'ID':train_id_,'Class':train_y_})\n",
        "samples = samples.drop_duplicates(keep='first')\n",
        "samples.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>422</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2677</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>201</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>423</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>496</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  Class\n",
              "0     422      2\n",
              "4    2677      5\n",
              "5     201      3\n",
              "29    423      2\n",
              "100   496      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "894SPjgRs_S7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb0d7f6-3c9f-4729-de48-ec6eeb3c1774"
      },
      "source": [
        "# 30% des échantillons de chaque classe affecté au jeu de validation\n",
        "train_id = []\n",
        "valid_id = []\n",
        "for c in np.unique(samples.Class.values) :\n",
        "    samples_c = samples.loc[samples.Class==c]\n",
        "    samples_frac = samples_c.sample(frac=0.7,random_state=1234) \n",
        "    train_id.extend( samples_frac.ID.values )\n",
        "    valid_id.extend( samples_c.drop(samples_frac.index).ID.values )\n",
        "len(train_id),len(valid_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1301, 558)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J609q3BrKRk"
      },
      "source": [
        "### **Récupération des positions des nouveaux échantillons d'entraînement et de validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmVBWpvFdjlk"
      },
      "source": [
        "# Récupérer les positions des nouveaux échantillons d'entraînement et validation\n",
        "idx_train = np.where ( np.isin(gt_id,train_id) )\n",
        "idx_valid = np.where ( np.isin(gt_id,valid_id) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U6m2R-UwEFK"
      },
      "source": [
        "### **Lire finalement les labels correspondant aux nouveaux échantillons d'entraînement, de validation et test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF_PEzn3vQzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3581715a-0bbf-4b0e-f0a9-233d19950605"
      },
      "source": [
        "train_y = gt_class[idx_train]\n",
        "valid_y = gt_class[idx_valid]\n",
        "test_y = gt_class[idx_test]\n",
        "train_y.shape, valid_y.shape, test_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((451962,), (153469,), (207485,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAt4KCeZR1Os"
      },
      "source": [
        "### **Lire finalement les identifiants correspondant aux nouveaux échantillons d'entraînement, de validation et test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3SiC0eVRvtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e936d58-e81c-4067-aae6-00e90a3319cc"
      },
      "source": [
        "# utile pour les aggrégations au niveau objet\n",
        "# train_id_array = gt_id[idx_train] # Pas vraiment nécessaire pour les échantillons d'entraînements\n",
        "valid_id_array = gt_id[idx_valid]\n",
        "test_id_array = gt_id[idx_test]\n",
        "#train_id_array.shape, \n",
        "valid_id_array.shape, test_id_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((153469,), (207485,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-8J5r9r3KI"
      },
      "source": [
        "### **Lire finalement les valeurs des séries temporelles correspondant aux nouveaux échantillons d'entraînement, de validation et test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRTUKBQBwd1V"
      },
      "source": [
        "#### **Pour un CNN2D ou spatial avec exemple d'imagettes ou patchs de 5 sur 5 en largeur et hauteur** \n",
        "\n",
        "Des patchs de 9 sur 9 sur l'ensemble des échantillons sont un peu trop gourmands en RAM pour Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBZ2s4zGwc8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65edd6bc-2cae-4a0f-8c2d-0db5bdbb73e6"
      },
      "source": [
        "# Un CNN 2D ou spatial requiert un tableau 3D du type (nombre d'échantillons, largeur, hauteur, nombre de features= (nombre de dates x nombre de bandes) )\n",
        "# Vous pouvez rajouter à la liste des bandes les indices spectraux normalisés que vous aurez calculé\n",
        "\n",
        "# Training\n",
        "# 1- précaution pour ne pas considérer les pixels dont on ne peut extraire des patchs car trop près du bord\n",
        "idx_col = idx_train[0]\n",
        "idx_row = idx_train[1]\n",
        "coords = np.column_stack((idx_col,idx_row))\n",
        "coords = coords[np.where( ( np.isin(coords[:,0],np.arange(2,blue_ts_norm.shape[0]-2,1)) ) & ( np.isin(coords[:,1],np.arange(2,blue_ts_norm.shape[1]-2,1)) ) ) ]\n",
        "# len(coords)\n",
        "# 2- créer un tableau avec les patchs\n",
        "train_X = []\n",
        "for coord in coords :\n",
        "  lst = []\n",
        "  for band in [blue_ts_norm,green_ts_norm,red_ts_norm,nir_ts_norm]:\n",
        "    lst.append( band[coord[0]-2:coord[0]+3,coord[1]-2:coord[1]+3] )\n",
        "  train_X.append(np.stack(lst,axis=-1).reshape(5,5,-1))\n",
        "train_X = np.stack(train_X,axis=0)\n",
        "train_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(451962, 5, 5, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhLlxu5j0O72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde2c125-4d5e-4f95-b00b-4b1fa43238b5"
      },
      "source": [
        "# Validation\n",
        "# 1- précaution pour ne pas considérer les pixels dont on ne peut extraire des patchs car trop près du bord\n",
        "idx_col = idx_valid[0]\n",
        "idx_row = idx_valid[1]\n",
        "coords = np.column_stack((idx_col,idx_row))\n",
        "coords = coords[np.where( ( np.isin(coords[:,0],np.arange(2,blue_ts_norm.shape[0]-2,1)) ) & ( np.isin(coords[:,1],np.arange(2,blue_ts_norm.shape[1]-2,1)) ) ) ]\n",
        "# len(coords)\n",
        "# 2- créer un tableau avec les patchs\n",
        "valid_X = []\n",
        "for coord in coords :\n",
        "  lst = []\n",
        "  for band in [blue_ts_norm,green_ts_norm,red_ts_norm,nir_ts_norm]:\n",
        "    lst.append( band[coord[0]-2:coord[0]+3,coord[1]-2:coord[1]+3] )\n",
        "  valid_X.append(np.stack(lst,axis=-1).reshape(5,5,-1))\n",
        "valid_X = np.stack(valid_X,axis=0)\n",
        "valid_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153469, 5, 5, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VR_nM9W0QkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e9f6dc-0f62-4b85-dd26-d1540cbf8b4b"
      },
      "source": [
        "# Test\n",
        "# 1- précaution pour ne pas considérer les pixels dont on ne peut extraire des patchs car trop près du bord\n",
        "idx_col = idx_test[0]\n",
        "idx_row = idx_test[1]\n",
        "coords = np.column_stack((idx_col,idx_row))\n",
        "coords = coords[np.where( ( np.isin(coords[:,0],np.arange(2,blue_ts_norm.shape[0]-2,1)) ) & ( np.isin(coords[:,1],np.arange(2,blue_ts_norm.shape[1]-2,1)) ) ) ]\n",
        "# len(coords)\n",
        "# 2- créer un tableau avec les patchs\n",
        "test_X = []\n",
        "for coord in coords :\n",
        "  lst = []\n",
        "  for band in [blue_ts_norm,green_ts_norm,red_ts_norm,nir_ts_norm]:\n",
        "    lst.append( band[coord[0]-2:coord[0]+3,coord[1]-2:coord[1]+3] )\n",
        "  test_X.append(np.stack(lst,axis=-1).reshape(5,5,-1))\n",
        "test_X = np.stack(test_X,axis=0)\n",
        "test_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(207485, 5, 5, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiqM_sYRt5IL"
      },
      "source": [
        "### **Sauvegarde des données d'entraînement, de validation et test en fichier numpy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPiv0fo3uJ8s"
      },
      "source": [
        "# Ainsi de cette façon vous pourrez continuer directement avec la création des modèles et en libérant la mémoire de tout ce qui a été fait précédemment\n",
        "Path('data').mkdir(exist_ok=True, parents=True)\n",
        "np.save('data/CNN2D/train_X.npy',train_X)\n",
        "np.save('data/CNN2D/train_y.npy',train_y)\n",
        "# np.save('data/train_id.npy',train_id_array)\n",
        "\n",
        "np.save('data/CNN2D/valid_X.npy',valid_X)\n",
        "np.save('data/CNN2D/valid_y.npy',valid_y)\n",
        "np.save('data/CNN2D/valid_id.npy',valid_id_array)\n",
        "\n",
        "np.save('data/CNN2D/test_X.npy',test_X)\n",
        "np.save('data/CNN2D/test_id.npy',test_id_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOM6_mv--8IX"
      },
      "source": [
        "Videz la mémoire en redémarrant l'environnement d'exécution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv0jts6w6nxr"
      },
      "source": [
        "# **Votre modèle de deep learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmBRjg3QFrLe"
      },
      "source": [
        "### **Remontage de Drive et Importation de quelques librairies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJUrD-aVMaN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b681ada-d464-4126-9ac0-d4c411b48209"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K5Xk6WeALcH"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tifffile\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Conv1D, GlobalAveragePooling1D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlRFSn7f_yKx"
      },
      "source": [
        "### **Recharger les données d'entraînement, de validation et test en fichier numpy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVzkEkQA-jM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d96ebf-a25e-4c13-b9c9-62d7a1cbb7fd"
      },
      "source": [
        "# Recharger les données après avoir vidé la mémoire\n",
        "train_X = np.load('data/CNN2D/train_X.npy')\n",
        "train_y = np.load('data/CNN2D/train_y.npy')\n",
        "\n",
        "valid_X = np.load('data/CNN2D/valid_X.npy')\n",
        "valid_y = np.load('data/CNN2D/valid_y.npy')\n",
        "valid_id = np.load('data/CNN2D/valid_id.npy')\n",
        "\n",
        "test_X = np.load('data/CNN2D/test_X.npy')\n",
        "test_id = np.load('data/CNN2D/test_id.npy')\n",
        "train_X.shape, train_y.shape, valid_X.shape, valid_y.shape, valid_id.shape, test_X.shape, test_id.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((451962, 5, 5, 32),\n",
              " (451962,),\n",
              " (153469, 5, 5, 32),\n",
              " (153469,),\n",
              " (153469,),\n",
              " (207485, 5, 5, 32),\n",
              " (207485,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K23T_c-EAj_z"
      },
      "source": [
        "### **Encoder les labels entre 0 et 4 de sorte à matcher les prédictions des réseaux de neurones**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY74aok1Arfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484b0336-3885-40e6-cdd3-4c96e5e598dc"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_y)\n",
        "train_y_enc = encoder.transform(train_y)\n",
        "valid_y_enc = encoder.transform(valid_y)\n",
        "np.unique(train_y), np.unique(train_y_enc), np.unique(valid_y), np.unique(valid_y_enc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 3, 4, 5], dtype=uint8),\n",
              " array([0, 1, 2, 3, 4]),\n",
              " array([1, 2, 3, 4, 5], dtype=uint8),\n",
              " array([0, 1, 2, 3, 4]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpH3oJPVE3uE"
      },
      "source": [
        "### **Définition séquentielle de votre modèle avec Keras**\n",
        "\n",
        "N'oubliez pas de spécifier l'input shape qui varie en fonction des types d'architectures, le nombre de neurones de la couche de sortie qui équivaut au nombre de classes que vous avez et de l'activer avec une fonction Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvUdNqlKAu0X"
      },
      "source": [
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(5, 5, 32)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(128, (1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1,1)))\n",
        "\n",
        "model.add(Conv2D(256, (1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1,1)))\n",
        " \n",
        "\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(5, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhhSzQvSFALk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a9e95e-8f93-4de4-cdb1-f87bffb733cb"
      },
      "source": [
        "# Afficher votre modèle\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_69 (Conv2D)           (None, 3, 3, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 1, 1, 128)         8320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 1, 1, 256)         33024     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 126,917\n",
            "Trainable params: 126,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2ksSpJGF1gP"
      },
      "source": [
        "### **Compiler votre modèle en définissant une fonction de côut, un optmiseur et une métrique**\n",
        "\n",
        "Dans le cas d'une classification multi-classe, votre fonction de coût est la cross entropy catégorique. $Adam$ est un bon optimiseur de départ pour vos projets. Ici vous pouvez surveiller la métrique $Accuracy$. Pour la fonction de coût (loss), je n'utilse pas l'argument $from\\_logits=True$ car j'ai déjà activé la couche de sortie avec une fonction Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtwtaGndG7UN"
      },
      "source": [
        "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLKCHopeIIet"
      },
      "source": [
        "### **Définir un callback pour sauver les poids de votre modèle sur les meilleures époque c'est à dire les moments où il s'améliorera sur le jeu de validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-_N87DhIH5N"
      },
      "source": [
        "Path('my_model').mkdir(exist_ok=True, parents=True)\n",
        "checkpointpath = os.path.join('my_model/CNN2D/TEST8','model') # chemin où sauver le modèle\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(\n",
        "              checkpointpath,\n",
        "              verbose=1, # niveau de log\n",
        "              monitor='val_acc', # nom de la métrique à surveiller\n",
        "              save_best_only=True, # sauver uniquement le meilleur modèle\n",
        "              save_weights_only=True)] # sauver uniquement les poids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WpxHz3FJuJ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3feab786-5ef7-4f28-e6a5-3843c8d2dc23"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "EPOCHS = 150\n",
        "model.fit (train_X, train_y_enc, validation_data=(valid_X,valid_y_enc), batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1763/1766 [============================>.] - ETA: 0s - loss: 0.3276 - acc: 0.8881\n",
            "Epoch 00001: val_acc improved from -inf to 0.91131, saving model to my_model/CNN2D/TEST8/model\n",
            "1766/1766 [==============================] - 11s 6ms/step - loss: 0.3274 - acc: 0.8881 - val_loss: 0.2441 - val_acc: 0.9113\n",
            "Epoch 2/150\n",
            "1765/1766 [============================>.] - ETA: 0s - loss: 0.2211 - acc: 0.9205\n",
            "Epoch 00002: val_acc did not improve from 0.91131\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.2211 - acc: 0.9205 - val_loss: 0.2543 - val_acc: 0.9110\n",
            "Epoch 3/150\n",
            "1761/1766 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9319\n",
            "Epoch 00003: val_acc improved from 0.91131 to 0.91882, saving model to my_model/CNN2D/TEST8/model\n",
            "1766/1766 [==============================] - 10s 5ms/step - loss: 0.1882 - acc: 0.9319 - val_loss: 0.2323 - val_acc: 0.9188\n",
            "Epoch 4/150\n",
            "1756/1766 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9410\n",
            "Epoch 00004: val_acc improved from 0.91882 to 0.91991, saving model to my_model/CNN2D/TEST8/model\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.1614 - acc: 0.9410 - val_loss: 0.2499 - val_acc: 0.9199\n",
            "Epoch 5/150\n",
            "1755/1766 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9488\n",
            "Epoch 00005: val_acc did not improve from 0.91991\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.1407 - acc: 0.9489 - val_loss: 0.2793 - val_acc: 0.9135\n",
            "Epoch 6/150\n",
            "1765/1766 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9541\n",
            "Epoch 00006: val_acc did not improve from 0.91991\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.1264 - acc: 0.9541 - val_loss: 0.3448 - val_acc: 0.8997\n",
            "Epoch 7/150\n",
            "1764/1766 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9585\n",
            "Epoch 00007: val_acc did not improve from 0.91991\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.1139 - acc: 0.9585 - val_loss: 0.3238 - val_acc: 0.8954\n",
            "Epoch 8/150\n",
            "1763/1766 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9626\n",
            "Epoch 00008: val_acc did not improve from 0.91991\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.1029 - acc: 0.9626 - val_loss: 0.3606 - val_acc: 0.9095\n",
            "Epoch 9/150\n",
            "1765/1766 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9658\n",
            "Epoch 00009: val_acc did not improve from 0.91991\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.0941 - acc: 0.9658 - val_loss: 0.3233 - val_acc: 0.9123\n",
            "Epoch 10/150\n",
            "1760/1766 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9688\n",
            "Epoch 00010: val_acc did not improve from 0.91991\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.0859 - acc: 0.9688 - val_loss: 0.3306 - val_acc: 0.9036\n",
            "Epoch 11/150\n",
            "1764/1766 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9712\n",
            "Epoch 00011: val_acc did not improve from 0.91991\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.0794 - acc: 0.9712 - val_loss: 0.3564 - val_acc: 0.9040\n",
            "Epoch 12/150\n",
            "1757/1766 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9735\n",
            "Epoch 00012: val_acc did not improve from 0.91991\n",
            "1766/1766 [==============================] - 9s 5ms/step - loss: 0.0729 - acc: 0.9735 - val_loss: 0.3595 - val_acc: 0.9099\n",
            "Epoch 13/150\n",
            "1760/1766 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9753"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-187-2c3e74c2d3bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_y_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1382\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_test_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \"\"\"\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_test_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozHZJ2CZH72X"
      },
      "source": [
        "### **Entraîner votre modèle pour un certain nombre d'époques**\n",
        "\n",
        "Le paramètre $validation\\_data$ vous permet de spécifier des données de validation et de votre le comportement de votre modèle sur un jeu indépendant dont il n'a pas la connaissance. \n",
        "\n",
        "La taille de batch ($batch\\_size$) correspond au nombre d'échantillons sur lesquels le modèle est entraîné à la fois sur une époque. Vous pouvez le mettre à (ex. 32, 64, 128, 256) et plus il est grand ce qui requiert d'avoir de la mémoire plus le temps d'exécution d'une époque sera court\n",
        "\n",
        "J'utilise les labels encodés entre 0 et 4 car la prédiction sur les distributions de probabilités du modèle est retournée avec un argmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8LxITTsM856"
      },
      "source": [
        "### **Restaurer les poids du modèle sur la meilleure époque d'entraînement**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1F4KMnnMz3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcda8d9-d1fe-4ee2-ba99-120c33790e61"
      },
      "source": [
        "model.load_weights(checkpointpath)\n",
        "# S'assurer que c'est bien le meilleur modèle sur les époques d'entraînement\n",
        "model.evaluate(valid_X,valid_y_enc,batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2499 - acc: 0.9199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24985112249851227, 0.9199121594429016]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh14_LtSPCqB"
      },
      "source": [
        "### **Prédiction des classes sur le jeu de validation et évaluation en aggrégeant au niveau objet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDpjyx_JPNjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0dcaceb-fd7e-4898-f911-1c0f20202f89"
      },
      "source": [
        "# Récupérer les probabilités prédites sur le jeu de validation\n",
        "valid_prob = model.predict(valid_X,batch_size=256)\n",
        "valid_prob.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153469, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26YozrngPZyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5f08b0-79d8-438c-f120-b4b102c13b9c"
      },
      "source": [
        "# Retourner la classe correspondant à la probabilité la plus haute\n",
        "valid_pred = np.argmax(valid_prob,axis=1) # axe 1 car ceci concerne chaque ligne\n",
        "valid_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153469,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Fyn2eyWU3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823a670b-debb-401f-b077-7dcfac256f27"
      },
      "source": [
        "# Je réencode les prédictions entre 1 et 5\n",
        "valid_pred_enc = encoder.inverse_transform(valid_pred)\n",
        "np.unique(valid_pred_enc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z35nADR_P-ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c488ea-4e67-47ac-b5e9-480ad1e851e1"
      },
      "source": [
        "# Aggrégation au niveau objet\n",
        "out_pred = []\n",
        "unique_id = np.unique(valid_id)\n",
        "for ID in unique_id :\n",
        "    # Récupérer les prédictions des pixels appartenant au même objet\n",
        "    pred = valid_pred_enc[np.where(valid_id==ID)]\n",
        "    y_true = valid_y[np.where(valid_id==ID)]\n",
        "    # Prendre la valeur majoritaire des prédictions sur les pixels\n",
        "    out_pred.append([ np.bincount(y_true).argmax(), np.bincount(pred).argmax()]) #(Vérité terrain,Prédiction majoritaire)\n",
        "out_pred = np.vstack(out_pred)\n",
        "out_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(558, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ2jDDDZWsKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8024283-35a0-4be1-c04e-0ba0b67a879f"
      },
      "source": [
        "# F1 score au niveau objet\n",
        "f1_score(out_pred[:,0],out_pred[:,1],average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9044447778240691"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIXYledyW9QI"
      },
      "source": [
        "### **Prédire sur le jeu test et Préparer une soumission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p--sBOPKW4SE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a58ac54-2e37-4545-962c-9a5657ea0364"
      },
      "source": [
        "# Récupérer les probabilités prédites sur le jeu test\n",
        "test_prob = model.predict(test_X,batch_size=256)\n",
        "test_prob.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(207485, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtI8FHPyXHF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ab2ac1-09bc-4f46-afa2-ad00c14aaa41"
      },
      "source": [
        "# Retourner la classe correspondant à la probabilité la plus haute\n",
        "test_pred = np.argmax(test_prob,axis=1) # axe 1 car ceci concerne chaque ligne\n",
        "test_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(207485,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4xPl0mFXNEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c693e6-9257-4980-b995-dfb0a9d5957e"
      },
      "source": [
        "# Je réencode les prédictions entre 1 et 5\n",
        "test_pred_enc = encoder.inverse_transform(test_pred)\n",
        "np.unique(test_pred_enc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khjM1qqMXTSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea11d6ba-86cd-46d2-f3ef-53cc33437747"
      },
      "source": [
        "# Aggrégation au niveau objet\n",
        "agg_pred = []\n",
        "unique_id = np.unique(test_id)\n",
        "for ID in unique_id :\n",
        "    # Récupérer les prédictions des pixels appartenant au même objet\n",
        "    pred = test_pred_enc[np.where(test_id==ID)]\n",
        "    # Prendre la valeur majoritaire des prédictions sur les pixels\n",
        "    agg_pred.append([ ID, np.bincount(pred).argmax()]) #(ID,Prédiction majoritaire)\n",
        "agg_pred = np.vstack(agg_pred)\n",
        "agg_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIdn628cEtgx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6b771795-f456-4ead-8430-e9f96910bb7f"
      },
      "source": [
        "df = pd.DataFrame({'ID':agg_pred[:,0],'Class':agg_pred[:,1]})\n",
        "df.to_csv('Soumission_CNN2D904.csv',index=False)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  Class\n",
              "0   4      5\n",
              "1   7      3\n",
              "2   8      5\n",
              "3   9      3\n",
              "4  10      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6WuuJCkXsu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a72f0470-ac3b-42d9-9019-f00785eb4e98"
      },
      "source": [
        "# F1 Score au niveau objet\n",
        "df_test = pd.read_csv('Test_ID_Label.csv') # Ce fichier vous sera fourni le 12 Novembre\n",
        "f1_score(df_test.Class,df.Class,average='weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8828627273172321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    }
  ]
}